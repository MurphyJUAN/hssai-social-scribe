# ================================
# 9. core/audio/transcriber.py - è½‰éŒ„æœå‹™
# ================================

import io
import os
import asyncio
import aiofiles
import logging
from typing import Tuple
from core.utils.retry import simple_retry
from core.audio.processor import AudioProcessor

logger = logging.getLogger(__name__)

class AudioTranscriber:
    """éŸ³é »è½‰éŒ„æœå‹™"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
    
    async def transcribe_chunk(self, chunk_path: str, chunk_index: int) -> Tuple[int, str, str]:
        """è½‰éŒ„å–®å€‹éŸ³é »åˆ†æ®µ"""
        try:
            logger.info(f"ğŸ¯ è½‰æ›åˆ†æ®µ {chunk_index}: {chunk_path}")
            
            if not os.path.exists(chunk_path):
                raise FileNotFoundError(f"åˆ†æ®µæ–‡ä»¶ä¸å­˜åœ¨: {chunk_path}")
            
            file_size = os.path.getsize(chunk_path)
            logger.info(f"ğŸ“ åˆ†æ®µ {chunk_index} å¤§å°: {file_size / 1024 / 1024:.2f}MB")
            
            # å¦‚æœæ–‡ä»¶å¤ªå¤§ï¼Œå˜—è©¦é¡å¤–å£“ç¸®
            processing_path = chunk_path
            if file_size > 8 * 1024 * 1024:  # 8MB
                logger.warning(f"âš ï¸ åˆ†æ®µ {chunk_index} éå¤§ï¼Œå˜—è©¦é¡å¤–å£“ç¸®...")
                extra_compressed_path = f"{chunk_path}_extra_compressed.mp3"
                
                success = await AudioProcessor.compress_audio(chunk_path, extra_compressed_path, aggressive=True)
                if success and os.path.exists(extra_compressed_path):
                    new_size = os.path.getsize(extra_compressed_path)
                    if new_size < file_size and new_size > 0:
                        processing_path = extra_compressed_path
                        logger.info(f"âœ… é¡å¤–å£“ç¸®æˆåŠŸ: {new_size / 1024 / 1024:.2f}MB")
            
            # è®€å–ä¸¦ç™¼é€åˆ° OpenAI
            async with aiofiles.open(processing_path, 'rb') as audio_file:
                audio_data = await audio_file.read()
                
                if not audio_data:
                    raise ValueError(f"åˆ†æ®µæ–‡ä»¶ç‚ºç©º: {processing_path}")
                
                audio_io = io.BytesIO(audio_data)
                audio_io.name = f"chunk_{chunk_index}.mp3"
                
                logger.info(f"ğŸ“¡ ç™¼é€åˆ†æ®µ {chunk_index} åˆ° OpenAI...")
                
                response = await self.openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_io,
                    response_format="verbose_json",
                    language="zh",
                    timeout=120.0
                )
                
                text = response.text
                logger.info(f"âœ… åˆ†æ®µ {chunk_index} è½‰æ›æˆåŠŸï¼Œæ–‡å­—é•·åº¦: {len(text)}")
                
                # æ¸…ç†é¡å¤–å£“ç¸®æ–‡ä»¶
                if processing_path != chunk_path:
                    try:
                        os.unlink(processing_path)
                    except:
                        pass
                
                return chunk_index, text, None
                
        except Exception as e:
            error_str = str(e)
            logger.error(f"âŒ åˆ†æ®µ {chunk_index} è½‰æ›å¤±æ•—: {error_str}")
            
            # åˆ¤æ–·éŒ¯èª¤é¡å‹
            if "413" in error_str or "too large" in error_str.lower():
                return chunk_index, "[æª”æ¡ˆéå¤§ï¼Œç„¡æ³•è™•ç†]", f"æª”æ¡ˆéå¤§: {error_str}"
            
            return chunk_index, "", error_str
    
    async def transcribe_chunk_with_retry(self, chunk_path: str, chunk_index: int, max_retries: int = 3) -> Tuple[int, str, str]:
        """å¸¶é‡è©¦æ©Ÿåˆ¶çš„è½‰éŒ„"""
        try:
            return await simple_retry(
                self.transcribe_chunk,
                chunk_path,
                chunk_index,
                max_retries=max_retries
            )
        except Exception as e:
            error_msg = f"åˆ†æ®µ {chunk_index} æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—: {str(e)}"
            logger.error(error_msg)
            return chunk_index, "", error_msg