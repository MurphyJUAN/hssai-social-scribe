# ================================
# 11. app/api/endpoints/transcription.py - è½‰éŒ„ç«¯é»
# ================================

import os
import math
import asyncio
import logging
from typing import List
from fastapi import APIRouter, UploadFile, File, HTTPException, Depends
from fastapi.responses import StreamingResponse

from app.config import Config
from app.dependencies import get_openai_client
from core.utils.sse import send_sse_data
from core.utils.file_utils import save_upload_file, cleanup_files, validate_audio_file
from core.audio.processor import AudioProcessor
from core.audio.splitter import AudioSplitter
from core.audio.transcriber import AudioTranscriber
from core.utils.text_converter import text_converter

logger = logging.getLogger(__name__)

router = APIRouter()

class TranscriptionService:
    """è½‰éŒ„æœå‹™ä¸»é‚è¼¯"""
    
    def __init__(self, openai_client):
        self.transcriber = AudioTranscriber(openai_client)
    
    async def process_audio_smart(self, file_path: str):
        """æ™ºèƒ½éŸ³é »è™•ç† - ä¸»è¦é‚è¼¯"""
        temp_files = []
        
        try:
            logger.info(f"ğŸ¬ é–‹å§‹æ™ºèƒ½è™•ç†éŸ³é »æ–‡ä»¶: {file_path}")
            
            # 1. åŸºæœ¬æª¢æŸ¥
            file_size = os.path.getsize(file_path)
            yield send_sse_data('progress', progress=5, message=f'æª”æ¡ˆå¤§å°: {file_size / 1024 / 1024:.1f}MB')
            
            # 2. ç²å–éŸ³é »è©³ç´°ä¿¡æ¯
            audio_info = await AudioProcessor.get_audio_info(file_path)
            duration_minutes = audio_info.get('duration_min', 0)
            
            if duration_minutes > 0:
                yield send_sse_data('progress', progress=10, 
                                  message=f'éŸ³é »é•·åº¦: {duration_minutes:.1f} åˆ†é˜')
                
                if duration_minutes > 30:
                    yield send_sse_data('progress', progress=12, 
                                      message='âš ï¸ éŸ³é »è¼ƒé•·ï¼Œå°‡æ¡ç”¨æ™ºèƒ½åˆ†å‰²ç­–ç•¥')
                elif duration_minutes > 15:
                    yield send_sse_data('progress', progress=12, 
                                      message='ğŸ’¡ éŸ³é »ä¸­ç­‰é•·åº¦ï¼Œå°‡å„ªåŒ–è™•ç†')
            
            # 3. æ±ºå®šè™•ç†ç­–ç•¥
            processing_file = file_path
            
            # å¦‚æœéŸ³é »å¾ˆé•·ï¼Œå„ªå…ˆæŒ‰æ™‚é•·åˆ†å‰²
            if duration_minutes > 10:
                yield send_sse_data('progress', progress=15, message='æ¡ç”¨æ™‚é•·åˆ†å‰²ç­–ç•¥...')
                
                chunks = await AudioSplitter.smart_split_by_duration(
                    file_path, duration_minutes, Config.MAX_SEGMENT_MINUTES
                )
                temp_files.extend([chunk for chunk in chunks if chunk != file_path])
                
                yield send_sse_data('progress', progress=30, 
                                  message=f'æŒ‰æ™‚é•·åˆ†å‰²å®Œæˆï¼Œå…± {len(chunks)} æ®µï¼ˆæ¯æ®µç´„ {Config.MAX_SEGMENT_MINUTES} åˆ†é˜ï¼‰')
            
            # å¦‚æœæ–‡ä»¶å¾ˆå¤§ä½†æ™‚é•·ä¸é•·ï¼ŒæŒ‰å¤§å°åˆ†å‰²
            elif file_size > Config.MAX_CHUNK_SIZE:
                yield send_sse_data('progress', progress=15, message='æª”æ¡ˆè¼ƒå¤§ï¼Œå…ˆå£“ç¸®...')
                
                compressed_path = f"{file_path}_compressed.mp3"
                temp_files.append(compressed_path)
                
                success = await AudioProcessor.compress_audio(file_path, compressed_path)
                if success and os.path.exists(compressed_path):
                    processing_file = compressed_path
                    new_size = os.path.getsize(compressed_path) / 1024 / 1024
                    yield send_sse_data('progress', progress=25, 
                                      message=f'å£“ç¸®å®Œæˆ: {new_size:.1f}MB')
                
                # æª¢æŸ¥å£“ç¸®å¾Œæ˜¯å¦é‚„éœ€è¦åˆ†å‰²
                if os.path.getsize(processing_file) > Config.MAX_CHUNK_SIZE:
                    chunks = await AudioSplitter.split_by_size(processing_file, Config.MAX_CHUNK_SIZE)
                    temp_files.extend([chunk for chunk in chunks if chunk != file_path and chunk != processing_file])
                else:
                    chunks = [processing_file]
                
                yield send_sse_data('progress', progress=30, 
                                  message=f'è™•ç†æº–å‚™å®Œæˆï¼Œå…± {len(chunks)} æ®µ')
            
            else:
                # å°æ–‡ä»¶ç›´æ¥è™•ç†
                chunks = [file_path]
                yield send_sse_data('progress', progress=30, message='æ–‡ä»¶å¤§å°é©ä¸­ï¼Œç›´æ¥è™•ç†')
            
            # 4. é©—è­‰åˆ†æ®µ
            valid_chunks = []
            for i, chunk_path in enumerate(chunks):
                if os.path.exists(chunk_path) and os.path.getsize(chunk_path) > 1024:
                    chunk_size = os.path.getsize(chunk_path) / 1024 / 1024
                    valid_chunks.append((chunk_path, i))
                    logger.info(f"âœ“ æœ‰æ•ˆåˆ†æ®µ {i}: {chunk_size:.1f}MB")
                else:
                    logger.error(f"âœ— ç„¡æ•ˆåˆ†æ®µ {i}: {chunk_path}")
            
            if not valid_chunks:
                raise ValueError("æ²’æœ‰æœ‰æ•ˆçš„éŸ³é »åˆ†æ®µ")
            
            # 5. æ™ºèƒ½è½‰æ›ç­–ç•¥
            yield send_sse_data('progress', progress=35, 
                              message=f'é–‹å§‹è½‰æ› {len(valid_chunks)} å€‹åˆ†æ®µ...')
            
            # æ ¹æ“šåˆ†æ®µæ•¸é‡èª¿æ•´ä¸¦ç™¼ç­–ç•¥
            batch_size, delay_between_batches = self._get_batch_strategy(len(valid_chunks))
            
            logger.info(f"ğŸ¯ è½‰æ›ç­–ç•¥: æ‰¹æ¬¡å¤§å°={batch_size}, å»¶é²={delay_between_batches}ç§’")
            
            results = {}
            total_chunks = len(valid_chunks)
            processed_chunks = 0
            failed_chunks = 0
            
            # 6. æ‰¹æ¬¡è™•ç†è½‰éŒ„
            for i in range(0, total_chunks, batch_size):
                batch_chunks = valid_chunks[i:i + batch_size]
                
                batch_info = f"ç¬¬ {i//batch_size + 1}/{math.ceil(total_chunks/batch_size)} æ‰¹"
                yield send_sse_data('progress', 
                                  progress=35 + (processed_chunks / total_chunks) * 50,
                                  message=f'è™•ç†{batch_info} ({len(batch_chunks)} æ®µ)...')
                
                # åŸ·è¡Œè½‰æ›
                tasks = [
                    self.transcriber.transcribe_chunk_with_retry(chunk_path, chunk_idx, max_retries=3)
                    for chunk_path, chunk_idx in batch_chunks
                ]
                
                try:
                    max_timeout = max(120, max(os.path.getsize(cp) for cp, _ in batch_chunks) / 1024 / 1024 * 30)
                    
                    batch_results = await asyncio.wait_for(
                        asyncio.gather(*tasks, return_exceptions=True),
                        timeout=max_timeout
                    )
                except asyncio.TimeoutError:
                    logger.error(f"âŒ æ‰¹æ¬¡ {i//batch_size + 1} è¶…æ™‚")
                    batch_results = [Exception("è½‰æ›è¶…æ™‚") for _ in batch_chunks]
                
                # è™•ç†çµæœ
                for result in batch_results:
                    if isinstance(result, Exception):
                        logger.error(f"âŒ æ‰¹æ¬¡è™•ç†ç•°å¸¸: {result}")
                        failed_chunks += 1
                        continue
                        
                    chunk_index, text, error = result
                    if error:
                        logger.error(f"âŒ åˆ†æ®µ {chunk_index} éŒ¯èª¤: {error}")
                        failed_chunks += 1
                        if "æª”æ¡ˆéå¤§" not in error:
                            results[chunk_index] = ""  # è¨˜éŒ„å¤±æ•—ä½†ç¹¼çºŒ
                    else:
                        results[chunk_index] = text
                        logger.info(f"âœ… åˆ†æ®µ {chunk_index} æˆåŠŸ: {len(text)} å­—")
                    
                    processed_chunks += 1
                
                # æ›´æ–°é€²åº¦
                progress = 35 + (processed_chunks / total_chunks) * 50
                success_rate = ((processed_chunks - failed_chunks) / processed_chunks * 100) if processed_chunks > 0 else 0
                yield send_sse_data('progress', progress=int(progress), 
                                  message=f'å·²å®Œæˆ {processed_chunks}/{total_chunks} æ®µ (æˆåŠŸç‡: {success_rate:.0f}%)')
                
                # æ‰¹æ¬¡é–“å»¶é²
                if i + batch_size < total_chunks:
                    yield send_sse_data('progress', progress=int(progress), 
                                      message=f'æš«åœ {delay_between_batches} ç§’ï¼Œé¿å… API é™åˆ¶...')
                    await asyncio.sleep(delay_between_batches)
            
            # 7. åˆä½µå’Œè¼¸å‡ºçµæœ
            async for chunk in self._finalize_results(results, chunks, total_chunks, failed_chunks, duration_minutes):
                yield chunk
                
        except Exception as e:
            logger.error(f"æ™ºèƒ½éŸ³é »è™•ç†å¤±æ•—: {str(e)}", exc_info=True)
            yield send_sse_data('error', 
                              error=f'è™•ç†å¤±æ•—: {str(e)}',
                              error_type=type(e).__name__)
        
        finally:
            # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
            cleanup_files(temp_files)
    
    def _get_batch_strategy(self, chunk_count: int):
        """æ ¹æ“šåˆ†æ®µæ•¸é‡ç²å–æ‰¹æ¬¡ç­–ç•¥"""
        if chunk_count > 5:
            return 1, 5  # å¤§é‡åˆ†æ®µæ™‚ä¸²è¡Œè™•ç†
        elif chunk_count > 3:
            return 2, 3
        else:
            return min(2, Config.MAX_CONCURRENT_TRANSCRIPTIONS), 2
    
    async def _finalize_results(self, results, chunks, total_chunks, failed_chunks, duration_minutes):
        """æœ€çµ‚åŒ–çµæœ"""
        yield send_sse_data('progress', progress=90, message='åˆä½µè½‰æ›çµæœ...')
        
        final_transcript = ""
        successful_chunks = len([r for r in results.values() if r])
        
        # æŒ‰é †åºåˆä½µ
        for i in range(len(chunks)):
            if i in results and results[i]:
                final_transcript += results[i] + " "
        
        if successful_chunks == 0:
            raise Exception(f"æ‰€æœ‰ {total_chunks} å€‹åˆ†æ®µéƒ½è½‰æ›å¤±æ•—")
        
        final_transcript = final_transcript.strip()
        final_transcript = " ".join(final_transcript.split())

        yield send_sse_data('progress', progress=92, message='è½‰æ›ç‚ºç¹é«”ä¸­æ–‡...')
        final_transcript = text_converter.to_traditional(final_transcript)
        logger.info(f"âœ… å·²è½‰æ›ç‚ºç¹é«”ä¸­æ–‡ï¼Œå…± {len(final_transcript)} å­—")
        
        success_rate = (successful_chunks / total_chunks) * 100
        
        # ä¸²æµç™¼é€çµæœ
        sentences = self._split_into_sentences(final_transcript)
        
        yield send_sse_data('progress', progress=95, 
                          message=f'é–‹å§‹ç™¼é€çµæœ... (å…± {len(sentences)} å¥)')
        
        for i, sentence in enumerate(sentences):
            if sentence:
                if not sentence.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
                    sentence += 'ã€‚'
                
                yield send_sse_data('chunk', 
                                  text=sentence,
                                  progress=95 + (i / len(sentences)) * 5)
                await asyncio.sleep(0.03)
        
        # å®Œæˆ
        yield send_sse_data('complete', 
                          progress=100, 
                          message=f'è™•ç†å®Œæˆï¼å…± {len(final_transcript)} å­— (æˆåŠŸç‡: {success_rate:.1f}%)',
                          stats={
                              'original_duration_minutes': duration_minutes,
                              'total_chunks': total_chunks,
                              'successful_chunks': successful_chunks,
                              'failed_chunks': failed_chunks,
                              'success_rate': success_rate,
                              'total_characters': len(final_transcript),
                              'total_sentences': len(sentences),
                              'processing_strategy': 'time_based' if duration_minutes > 10 else 'size_based'
                          })
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """å°‡æ–‡æœ¬åˆ†å‰²æˆå¥å­"""
        sentences = []
        for delimiter in ['ã€‚', 'ï¼', 'ï¼Ÿ']:
            text = text.replace(delimiter, delimiter + '|')
        
        sentences = [s.strip() for s in text.split('|') if s.strip()]
        return sentences


@router.post("/transcribe")
async def transcribe_audio_smart(
    audio: UploadFile = File(...),
    openai_client = Depends(get_openai_client)
):
    """æ™ºèƒ½éŸ³é »è½‰æ–‡å­— API - ä¿®å¾©ç‰ˆæœ¬"""
    
    # ğŸ”‘ ä¿®å¾©ï¼šå…ˆè®€å–å…§å®¹é€²è¡Œé©—è­‰ï¼Œç„¶å¾Œé‡ç½®æŒ‡é‡
    content = await audio.read()
    file_size = len(content)
    
    try:
        validate_audio_file(audio.filename, file_size, Config.SUPPORTED_FORMATS, Config.MAX_FILE_SIZE)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    logger.info(f"ğŸ“ æ”¶åˆ°éŸ³é »æ–‡ä»¶: {audio.filename}, å¤§å°: {file_size / 1024 / 1024:.2f}MB")
    
    # ğŸ”‘ ä¿®å¾©ï¼šé‡ç½®æ–‡ä»¶æŒ‡é‡ï¼Œç„¶å¾Œä¿å­˜æ–‡ä»¶
    await audio.seek(0)  # é‡è¦ï¼šé‡ç½®æ–‡ä»¶æŒ‡é‡åˆ°é–‹é ­
    file_extension = audio.filename.split('.')[-1].lower()
    temp_file_path = await save_upload_file(audio, suffix=f".{file_extension}")
    
    # å‰µå»ºè½‰éŒ„æœå‹™
    service = TranscriptionService(openai_client)
    
    async def generate_response():
        try:
            yield send_sse_data('progress', progress=0, message='æ­£åœ¨åˆ†æéŸ³é »æ–‡ä»¶...')
            
            # ä½¿ç”¨æ™ºèƒ½è™•ç†å‡½æ•¸
            async for chunk in service.process_audio_smart(temp_file_path):
                yield chunk
                
        except Exception as e:
            logger.error(f"è™•ç†éŒ¯èª¤: {str(e)}", exc_info=True)
            
            # æä¾›æ›´è©³ç´°çš„éŒ¯èª¤ä¿¡æ¯
            error_message = str(e)
            if "502" in error_message or "Bad Gateway" in error_message:
                error_message = "OpenAI æœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦"
            elif "timeout" in error_message.lower():
                error_message = "è«‹æ±‚è¶…æ™‚ï¼Œæª”æ¡ˆå¯èƒ½éå¤§ï¼Œå»ºè­°åˆ†æ®µä¸Šå‚³"
            elif "413" in error_message or "too large" in error_message.lower():
                error_message = "æª”æ¡ˆéå¤§ï¼Œè«‹å£“ç¸®å¾Œå†è©¦æˆ–åˆ†æ®µä¸Šå‚³"
            
            yield send_sse_data('error', error=error_message)
            
        finally:
            cleanup_files([temp_file_path])
    
    return StreamingResponse(
        generate_response(),
        media_type='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Content-Type': 'text/event-stream; charset=utf-8',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Cache-Control',
            'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
            'X-Accel-Buffering': 'no'
        }
    )
