// composables/useRecording.ts
import { ref, computed } from 'vue'
import { useProjectStore } from '@/stores/useProjectStore'

export function useRecording() {
  const projectStore = useProjectStore()

  const mediaRecorder = ref<MediaRecorder | null>(null)
  const audioChunks = ref<Blob[]>([])
  const stream = ref<MediaStream | null>(null)

  // ðŸ”‘ æ–°å¢žï¼šæœ€å¤§éŒ„éŸ³æ™‚é–“ï¼ˆ90åˆ†é˜ = 5400ç§’ï¼‰
  const MAX_RECORDING_TIME = 90 * 60 // 5400ç§’

  const isRecording = computed(() => projectStore.isRecording)
  const isPaused = computed(() => projectStore.isPaused)
  const recordingTime = computed(() => projectStore.recordingTime)

  // ðŸ”‘ æ–°å¢žï¼šå‰©é¤˜æ™‚é–“è¨ˆç®—
  const remainingTime = computed(() => {
    return Math.max(0, MAX_RECORDING_TIME - projectStore.recordingTime)
  })

  // ðŸ”‘ æ–°å¢žï¼šæ˜¯å¦æŽ¥è¿‘æ™‚é–“é™åˆ¶
  const isNearTimeLimit = computed(() => {
    return projectStore.recordingTime > MAX_RECORDING_TIME * 0.9 // 90%æ™‚è­¦å‘Š
  })

  let recordingTimer: number | null = null

  // é–‹å§‹éŒ„éŸ³
  const startRecording = async (): Promise<void> => {
    try {
      stream.value = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        }
      })

      // é¸æ“‡æœ€ä½³çš„éŒ„éŸ³æ ¼å¼
      const options: MediaRecorderOptions = {}
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
        options.mimeType = 'audio/webm;codecs=opus'
      } else if (MediaRecorder.isTypeSupported('audio/webm')) {
        options.mimeType = 'audio/webm'
      } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
        options.mimeType = 'audio/mp4'
      } else if (MediaRecorder.isTypeSupported('audio/wav')) {
        options.mimeType = 'audio/wav'
      }

      mediaRecorder.value = new MediaRecorder(stream.value, options)
      audioChunks.value = []

      mediaRecorder.value.ondataavailable = (event: BlobEvent) => {
        if (event.data.size > 0) {
          audioChunks.value.push(event.data)
        }
      }

      mediaRecorder.value.onstop = () => {
        const mimeType = mediaRecorder.value?.mimeType || 'audio/wav'
        const fileExtension = getFileExtensionFromMimeType(mimeType)

        const audioBlob = new Blob(audioChunks.value, { type: mimeType })
        const audioFile = new File([audioBlob], `recording_${Date.now()}.${fileExtension}`, {
          type: mimeType,
          lastModified: Date.now()
        })
        const audioUrl = URL.createObjectURL(audioBlob)

        projectStore.setAudioFile(audioFile, audioUrl)
        stopTimer()
      }

      // è¨­å®šéŒ„éŸ³ç‰‡æ®µé–“éš”ï¼ˆæ¯ç§’è¨˜éŒ„ä¸€æ¬¡ï¼‰
      mediaRecorder.value.start(1000)
      projectStore.isRecording = true
      projectStore.recordingTime = 0
      startTimer()
    } catch (error) {
      console.error('ç„¡æ³•é–‹å§‹éŒ„éŸ³:', error)
      throw new Error('ç„¡æ³•é–‹å§‹éŒ„éŸ³ï¼Œè«‹æª¢æŸ¥éº¥å…‹é¢¨æ¬Šé™')
    }
  }

  // æ ¹æ“š MIME é¡žåž‹ç²å–æª”æ¡ˆå‰¯æª”å
  const getFileExtensionFromMimeType = (mimeType: string): string => {
    const typeMap: Record<string, string> = {
      'audio/webm': 'webm',
      'audio/webm;codecs=opus': 'webm',
      'audio/mp4': 'm4a',
      'audio/wav': 'wav',
      'audio/ogg': 'ogg'
    }
    return typeMap[mimeType] || 'wav'
  }

  // æš«åœéŒ„éŸ³
  const pauseRecording = (): void => {
    if (mediaRecorder.value && mediaRecorder.value.state === 'recording') {
      mediaRecorder.value.pause()
      projectStore.isRecording = false
      projectStore.isPaused = true
      stopTimer()
    }
  }

  // æ¢å¾©éŒ„éŸ³
  const resumeRecording = (): void => {
    if (mediaRecorder.value && mediaRecorder.value.state === 'paused') {
      mediaRecorder.value.resume()
      projectStore.isRecording = true
      projectStore.isPaused = false
      startTimer()
    }
  }

  // åœæ­¢éŒ„éŸ³
  const stopRecording = (): void => {
    if (mediaRecorder.value && mediaRecorder.value.state !== 'inactive') {
      mediaRecorder.value.stop()

      if (stream.value) {
        stream.value.getTracks().forEach((track) => track.stop())
      }

      projectStore.isRecording = false
      projectStore.isPaused = false
      stopTimer()
    }
  }

  // ðŸ”‘ ä¿®æ”¹ï¼šè¨ˆæ™‚å™¨åŠ å…¥æ™‚é–“é™åˆ¶æª¢æŸ¥
  const startTimer = (): void => {
    recordingTimer = window.setInterval(() => {
      projectStore.recordingTime++

      // ðŸ”‘ æª¢æŸ¥æ˜¯å¦é”åˆ°æœ€å¤§éŒ„éŸ³æ™‚é–“
      if (projectStore.recordingTime >= MAX_RECORDING_TIME) {
        console.log('â° é”åˆ°æœ€å¤§éŒ„éŸ³æ™‚é–“ï¼ˆ90åˆ†é˜ï¼‰ï¼Œè‡ªå‹•åœæ­¢éŒ„éŸ³')
        stopRecording()
      }
    }, 1000)
  }

  const stopTimer = (): void => {
    if (recordingTimer) {
      clearInterval(recordingTimer)
      recordingTimer = null
    }
  }

  // æ ¼å¼åŒ–éŒ„éŸ³æ™‚é–“
  const formatRecordingTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  // ðŸ”‘ æ–°å¢žï¼šæ ¼å¼åŒ–å‰©é¤˜æ™‚é–“
  const formatRemainingTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  return {
    isRecording,
    isPaused,
    recordingTime,
    startRecording,
    pauseRecording,
    resumeRecording,
    stopRecording,
    formatRecordingTime,
    // ðŸ”‘ æ–°å¢žçš„è¿”å›žå€¼
    remainingTime,
    formatRemainingTime,
    isNearTimeLimit,
    maxRecordingTimeMinutes: 90
  }
}
